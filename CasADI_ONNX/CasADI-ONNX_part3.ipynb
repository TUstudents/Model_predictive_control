{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4967b1f",
      "metadata": {},
      "source": [
        "# Tutorial: PyTorch to CasADi NMPC via ONNX\n",
        "## Part 3: Closed-Loop Simulation and Analysis\n",
        "\n",
        "In Part 1, we trained a PyTorch ANN and exported it to ONNX. In Part 2, we imported this ONNX model into CasADi and formulated a Nonlinear Model Predictive Control (NMPC) problem using this ANN as the predictive model.\n",
        "\n",
        "Now, in Part 3, we will:\n",
        "1.  Implement the NMPC receding horizon control loop.\n",
        "2.  Simulate the \"true\" Van der Pol oscillator (our plant) being controlled by the ANN-NMPC.\n",
        "3.  Log and visualize the closed-loop performance: state trajectories, control inputs, and constraint satisfaction.\n",
        "4.  Discuss the results and potential considerations when using data-driven models in MPC.\n",
        "\n",
        "**Prerequisites:** Completion of Part 1 and Part 2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "787ded50",
      "metadata": {},
      "source": [
        "### 3.1 Importing Libraries and Re-using Setup from Part 2\n",
        "\n",
        "We'll bring in the necessary libraries and the CasADi `Opti()` object (`opti_vdp`) and the ONNX wrapper function (`f_ann_mpc_casadi`) that we created in Part 2. We also need the true plant model (`vdp_ode`) and its parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bea9d277",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR: Scaler .pkl files not found. Please run Part 1 first to generate and save them!\n",
            "Error creating CasADi ONNX wrapper: .../casadi/core/casadi_os.cpp:166: Assertion \"handle!=nullptr\" failed:\n",
            "DllLibrary::init_handle: Cannot load shared library 'vdp_ann_model.onnx': \n",
            "   (\n",
            "    Searched directories: 1. casadipath from GlobalOptions\n",
            "                          2. CASADIPATH env var\n",
            "                          3. PATH env var (Windows)\n",
            "                          4. LD_LIBRARY_PATH env var (Linux)\n",
            "                          5. DYLD_LIBRARY_PATH env var (osx)\n",
            "    A library may be 'not found' even if the file exists:\n",
            "          * library is not compatible (different compiler/bitness)\n",
            "          * the dependencies are not found\n",
            "   )\n",
            "  Tried '/home/tensor/Model_predictive_control/.venv/lib/python3.12/site-packages/casadi' :\n",
            "    Error code: /home/tensor/Model_predictive_control/.venv/lib/python3.12/site-packages/casadi/vdp_ann_model.onnx: cannot open shared object file: No such file or directory\n",
            "  Tried '' :\n",
            "    Error code: vdp_ann_model.onnx: cannot open shared object file: No such file or directory\n",
            "  Tried '.' :\n",
            "    Error code: ./vdp_ann_model.onnx: invalid ELF header. NMPC simulation will not run.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import solve_ivp\n",
        "import casadi as ca\n",
        "from sklearn.preprocessing import MinMaxScaler # For scalers\n",
        "import joblib # For loading scalers\n",
        "import onnx # For ONNX model path definition\n",
        "import torch # For loading PyTorch model to get weights if needed (for re-implementation method)\n",
        "import torch.nn as nn # For model definition if re-implementing for verification\n",
        "\n",
        "plt.rcParams.update({'font.size': 12, 'figure.figsize': (12, 8)}) \n",
        "\n",
        "# --- Parameters and Functions from Part 1 & 2 ---\n",
        "# Van der Pol parameters\n",
        "mu_vdp = 1.0\n",
        "n_x = 2 # x1, x2\n",
        "n_u = 1 # u\n",
        "Ts_mpc_vdp = 0.1 # Control interval, should match ANN training data sampling if ANN predicts x_k+1\n",
        "\n",
        "def vdp_ode(t, x_state, u_input, mu):\n",
        "    x1, x2 = x_state\n",
        "    dx1_dt = x2\n",
        "    dx2_dt = mu * (1 - x1**2) * x2 - x1 + u_input\n",
        "    return [dx1_dt, dx2_dt]\n",
        "\n",
        "# Load scalers (essential!)\n",
        "try:\n",
        "    input_feature_scaler = joblib.load('input_feature_scaler.pkl')\n",
        "    output_target_scaler = joblib.load('output_target_scaler.pkl')\n",
        "    print(\"Loaded scalers from Part 1.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: Scaler .pkl files not found. Please run Part 1 first to generate and save them!\")\n",
        "    # Create dummy scalers to allow rest of notebook to be defined, but it won't work correctly.\n",
        "    input_feature_scaler = MinMaxScaler(feature_range=(-1, 1)); input_feature_scaler.fit(np.random.rand(10, n_x + n_u))\n",
        "    output_target_scaler = MinMaxScaler(feature_range=(-1, 1)); output_target_scaler.fit(np.random.rand(10, n_x))\n",
        "\n",
        "onnx_model_filepath = \"vdp_ann_model.onnx\"\n",
        "ann_input_dim = n_x + n_u\n",
        "ann_output_dim = n_x\n",
        "\n",
        "# --- CasADi ONNX Function and Wrapper (from Part 2) ---\n",
        "f_ann_mpc_casadi = None\n",
        "try:\n",
        "    onnx_casadi_func_scaled = ca.external('f_onnx_scaled_part3', onnx_model_filepath) # Use a new name if run in same session\n",
        "    input_min_np = input_feature_scaler.min_\n",
        "    input_scale_np = input_feature_scaler.scale_\n",
        "    output_min_np = output_target_scaler.min_\n",
        "    output_scale_np = output_target_scaler.scale_\n",
        "\n",
        "    sx_k_unscaled = ca.SX.sym('sx_k_unscaled_w', n_x)\n",
        "    su_k_unscaled = ca.SX.sym('su_k_unscaled_w', n_u)\n",
        "    s_ann_input_unscaled = ca.vertcat(sx_k_unscaled, su_k_unscaled)\n",
        "    s_ann_input_scaled = (s_ann_input_unscaled - input_min_np.reshape(-1,1)) * input_scale_np.reshape(-1,1)\n",
        "    s_ann_output_scaled = onnx_casadi_func_scaled(s_ann_input_scaled)\n",
        "    sx_k_plus_1_unscaled = s_ann_output_scaled / output_scale_np.reshape(-1,1) + output_min_np.reshape(-1,1)\n",
        "    \n",
        "    f_ann_mpc_casadi = ca.Function('f_ann_mpc_final', \n",
        "                                   [sx_k_unscaled, su_k_unscaled], \n",
        "                                   [sx_k_plus_1_unscaled],\n",
        "                                   ['xk', 'uk'], ['xk_plus_1'])\n",
        "    print(\"CasADi ONNX wrapper function ready.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating CasADi ONNX wrapper: {e}. NMPC simulation will not run.\")\n",
        "\n",
        "# --- NMPC Formulation (from Part 2) ---\n",
        "opti_vdp = None # Will be defined if f_ann_mpc_casadi is available\n",
        "if f_ann_mpc_casadi:\n",
        "    Np_vdp = 15\n",
        "    Q_x1_vdp = 20.0; Q_x2_vdp = 2.0; R_u_vdp = 0.05; S_u_vdp = 0.1\n",
        "    u_min_vdp = -2.0; u_max_vdp = 2.0; delta_u_max_vdp = 0.5\n",
        "    x1_min_vdp = -2.5; x1_max_vdp = 2.5; x2_min_vdp = -3.0; x2_max_vdp = 3.0\n",
        "    x1_sp_target_vdp = 0.0; x2_sp_target_vdp = 0.0\n",
        "\n",
        "    opti_vdp = ca.Opti()\n",
        "    X_sym_vdp = opti_vdp.variable(n_x, Np_vdp + 1)\n",
        "    U_sym_vdp = opti_vdp.variable(n_u, Np_vdp)\n",
        "    x0_vdp_param = opti_vdp.parameter(n_x)\n",
        "    u_prev_vdp_param = opti_vdp.parameter(n_u)\n",
        "    x1_sp_vdp_param = opti_vdp.parameter(Np_vdp)\n",
        "    x2_sp_vdp_param = opti_vdp.parameter(Np_vdp)\n",
        "    obj_vdp = 0\n",
        "    for j in range(Np_vdp):\n",
        "        obj_vdp += Q_x1_vdp * (X_sym_vdp[0, j+1] - x1_sp_vdp_param[j])**2\n",
        "        obj_vdp += Q_x2_vdp * (X_sym_vdp[1, j+1] - x2_sp_vdp_param[j])**2\n",
        "        obj_vdp += R_u_vdp * (U_sym_vdp[0, j])**2\n",
        "        delta_u_vdp = U_sym_vdp[0, j] - (u_prev_vdp_param[0] if j==0 else U_sym_vdp[0, j-1])\n",
        "        obj_vdp += S_u_vdp * delta_u_vdp**2\n",
        "    opti_vdp.minimize(obj_vdp)\n",
        "    opti_vdp.subject_to(X_sym_vdp[:,0] == x0_vdp_param)\n",
        "    for j in range(Np_vdp):\n",
        "        x_next_pred_vdp = f_ann_mpc_casadi(X_sym_vdp[:,j], U_sym_vdp[:,j])\n",
        "        opti_vdp.subject_to(X_sym_vdp[:,j+1] == x_next_pred_vdp)\n",
        "        opti_vdp.subject_to(opti_vdp.bounded(u_min_vdp, U_sym_vdp[0,j], u_max_vdp))\n",
        "        delta_u_constr_vdp = U_sym_vdp[0,j] - (u_prev_vdp_param[0] if j==0 else U_sym_vdp[0,j-1])\n",
        "        opti_vdp.subject_to(opti_vdp.bounded(-delta_u_max_vdp, delta_u_constr_vdp, delta_u_max_vdp))\n",
        "        opti_vdp.subject_to(opti_vdp.bounded(x1_min_vdp, X_sym_vdp[0,j+1], x1_max_vdp))\n",
        "        opti_vdp.subject_to(opti_vdp.bounded(x2_min_vdp, X_sym_vdp[1,j+1], x2_max_vdp))\n",
        "    nlp_opts_vdp = {'ipopt.print_level': 0, 'print_time': 0, 'ipopt.max_iter': 150,\n",
        "                    'ipopt.acceptable_tol': 1e-5, 'ipopt.acceptable_obj_change_tol': 1e-5}\n",
        "    opti_vdp.solver('ipopt', nlp_opts_vdp)\n",
        "    print(\"NMPC problem for VDP ANN-MPC ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3977b037",
      "metadata": {},
      "source": [
        "### 3.2 Implementing the Receding Horizon Control Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "58058b94",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANN-NMPC simulation skipped due to earlier errors in ONNX wrapper setup.\n"
          ]
        }
      ],
      "source": [
        "if f_ann_mpc_casadi and opti_vdp:\n",
        "    # Simulation Parameters\n",
        "    sim_duration = 10.0 # seconds\n",
        "    num_sim_steps = int(sim_duration / Ts_mpc_vdp)\n",
        "\n",
        "    # Plant initial condition and previous input\n",
        "    x_plant_current = np.array([1.5, 0.5]) # Start away from origin\n",
        "    u_plant_prev = np.array([0.0])\n",
        "\n",
        "    # Setpoint trajectory (stabilize to origin)\n",
        "    x1_sp_horizon = np.full(Np_vdp, x1_sp_target_vdp)\n",
        "    x2_sp_horizon = np.full(Np_vdp, x2_sp_target_vdp)\n",
        "\n",
        "    # Data Logging\n",
        "    t_history = np.zeros(num_sim_steps + 1)\n",
        "    x_history_plant = np.zeros((n_x, num_sim_steps + 1))\n",
        "    u_history_mpc = np.zeros((n_u, num_sim_steps))\n",
        "    solver_time_history = np.zeros(num_sim_steps)\n",
        "\n",
        "    x_history_plant[:, 0] = x_plant_current\n",
        "    t_history[0] = 0\n",
        "\n",
        "    # Initial guess for NMPC solver (can be important for convergence)\n",
        "    # Warm starting: use previous solution shifted\n",
        "    U_guess_mpc = np.zeros((n_u, Np_vdp)) \n",
        "    X_guess_mpc = np.tile(x_plant_current.reshape(n_x,1), (1, Np_vdp + 1))\n",
        "\n",
        "    print(f\"Starting ANN-NMPC simulation for {num_sim_steps} steps...\")\n",
        "    for k_step in range(num_sim_steps):\n",
        "        current_time_sim = k_step * Ts_mpc_vdp\n",
        "        print(f\"Sim Step {k_step+1}/{num_sim_steps} (t={current_time_sim:.2f}s)\", end='\\r')\n",
        "\n",
        "        # Set parameters for the Opti problem\n",
        "        opti_vdp.set_value(x0_vdp_param, x_plant_current)\n",
        "        opti_vdp.set_value(u_prev_vdp_param, u_plant_prev)\n",
        "        opti_vdp.set_value(x1_sp_vdp_param, x1_sp_horizon)\n",
        "        opti_vdp.set_value(x2_sp_vdp_param, x2_sp_horizon)\n",
        "\n",
        "        # Set initial guess for solver (warm start)\n",
        "        opti_vdp.set_initial(X_sym_vdp, X_guess_mpc)\n",
        "        opti_vdp.set_initial(U_sym_vdp, U_guess_mpc)\n",
        "\n",
        "        try:\n",
        "            sol = opti_vdp.solve()\n",
        "            U_optimal_sequence = sol.value(U_sym_vdp)\n",
        "            X_predicted_sequence = sol.value(X_sym_vdp) # For updating guess\n",
        "            u_applied_to_plant = U_optimal_sequence[:, 0]\n",
        "            solver_time_history[k_step] = sol.stats()['t_wall_total']\n",
        "\n",
        "            # Update guess for next iteration (shift)\n",
        "            X_guess_mpc = np.hstack((X_predicted_sequence[:, 1:], X_predicted_sequence[:, -1].reshape(n_x,1)))\n",
        "            U_guess_mpc = np.hstack((U_optimal_sequence[:, 1:], U_optimal_sequence[:, -1].reshape(n_u,1)))\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(f\"\\nSolver failed at step {k_step+1}: {e}. Using previous control.\")\n",
        "            u_applied_to_plant = u_plant_prev.flatten()\n",
        "            solver_time_history[k_step] = np.nan # Indicate failure\n",
        "            # Reset guess to something safe if solver fails repeatedly\n",
        "            U_guess_mpc = np.zeros((n_u, Np_vdp))\n",
        "            X_guess_mpc = np.tile(x_plant_current.reshape(n_x,1), (1, Np_vdp + 1))\n",
        "            \n",
        "        u_history_mpc[:, k_step] = u_applied_to_plant\n",
        "\n",
        "        # Simulate true plant for one step\n",
        "        plant_sol_step = solve_ivp(vdp_ode, \n",
        "                                   [current_time_sim, current_time_sim + Ts_mpc_vdp], \n",
        "                                   x_plant_current, \n",
        "                                   args=(u_applied_to_plant[0], mu_vdp), \n",
        "                                   method='RK45', dense_output=False, \n",
        "                                   t_eval=[current_time_sim + Ts_mpc_vdp])\n",
        "        x_plant_current = plant_sol_step.y[:,-1]\n",
        "\n",
        "        x_history_plant[:, k_step+1] = x_plant_current\n",
        "        t_history[k_step+1] = current_time_sim + Ts_mpc_vdp\n",
        "        u_plant_prev = u_applied_to_plant.reshape(n_u, 1)\n",
        "        \n",
        "    print(\"\\nANN-NMPC simulation finished.\")\n",
        "else:\n",
        "    print(\"ANN-NMPC simulation skipped due to earlier errors in ONNX wrapper setup.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6bdf569",
      "metadata": {},
      "source": [
        "### 3.3 Visualization and Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fa88e71a",
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unmatched ']' (2779125785.py, line 17)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31maxs_n_x].axhline(u_min_vdp, color='m', linestyle='--', label='$u_{min}$')\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ']'\n"
          ]
        }
      ],
      "source": [
        "if f_ann_mpc_casadi and opti_vdp:\n",
        "    fig, axs = plt.subplots(n_x + 1, 1, figsize=(10, 8), sharex=True)\n",
        "    fig.suptitle('ANN-NMPC Control of Van der Pol Oscillator', fontsize=16)\n",
        "\n",
        "    # Plot states\n",
        "    state_labels_vdp = ['$x_1$ (position)', '$x_2$ (velocity)']\n",
        "    sp_labels_vdp = [x1_sp_target_vdp, x2_sp_target_vdp]\n",
        "    for i in range(n_x):\n",
        "        axs[i].plot(t_history, x_history_plant[i, :], 'b-', label=f'{state_labels_vdp[i]} (Plant)')\n",
        "        axs[i].axhline(sp_labels_vdp[i], color='r', linestyle=':', label=f'Setpoint $x_{i+1,sp}$')\n",
        "        axs[i].set_ylabel(state_labels_vdp[i])\n",
        "        axs[i].grid(True); axs[i].legend()\n",
        "\n",
        "    # Plot control input\n",
        "    axs[n_x].step(t_history[:-1], u_history_mpc[0, :], 'k-', where='post', label='Control Input $u$ ($T_c$)')\n",
        "    axs[n_x].axhline(u_max_vdp, color='m', linestyle='--', label='$u_{max}$')\n",
        "    axs_n_x].axhline(u_min_vdp, color='m', linestyle='--', label='$u_{min}$')\n",
        "    axs[n_x].set_ylabel('Input $u$')\n",
        "    axs[n_x].set_xlabel('Time (s)')\n",
        "    axs[n_x].grid(True); axs[n_x].legend()\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n",
        "\n",
        "    # Plot solver times\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(t_history[:-1], solver_time_history * 1000, 'o-')\n",
        "    plt.title('NMPC Solver Time per Step')\n",
        "    plt.xlabel('Time (s)'); plt.ylabel('Solver Time (ms)')\n",
        "    plt.grid(True); plt.show()\n",
        "    print(f\"Average solver time: {np.nanmean(solver_time_history)*1000:.2f} ms\")\n",
        "    print(f\"Max solver time: {np.nanmax(solver_time_history)*1000:.2f} ms (Sample time Ts={Ts_mpc_vdp*1000} ms)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63b58a6f",
      "metadata": {},
      "source": [
        "### 3.4 Discussion and Troubleshooting\n",
        "\n",
        "*   **Performance:** How well did the ANN-NMPC stabilize the Van der Pol oscillator or track setpoints? Did it respect constraints?\n",
        "*   **Model Accuracy:** The performance heavily relies on how well the ANN (imported via ONNX) approximates the true system dynamics within the operating region encountered during control. If the ANN model has significant errors, the MPC's predictions will be off, leading to suboptimal or unstable control.\n",
        "*   **Extrapolation:** If the MPC drives the system into regions where the ANN was not well-trained, the ANN's predictions (and thus the control actions) can become unreliable. This is a key risk with data-driven models.\n",
        "*   **Computational Time:** Monitor the solver time. Is it consistently within the sampling interval $T_s$? The complexity of the ANN (number of layers/neurons) directly impacts the evaluation time within each NLP iteration.\n",
        "*   **Solver Issues:** \n",
        "    *   Did the NLP solver (IPOPT) converge at every step? Failures can occur due to poor initial guesses, model inaccuracies leading to difficult optimization landscapes, or ill-conditioning.\n",
        "    *   Warm-starting (using the previous solution as a guess) is crucial for improving convergence speed and reliability.\n",
        "*   **ONNX Operator Support:** The success of `ca.external` with an ONNX file depends on CasADi's ability to interpret all ONNX operators in the graph symbolically for AD. Simpler ANNs (e.g., using standard layers like `Linear`, `ReLU`, `Tanh`) are more likely to be fully supported than exotic custom layers.\n",
        "*   **Scaling Consistency:** Double-check that the scaling applied in the CasADi wrapper exactly matches the scaling used during the PyTorch ANN training. Any mismatch here will lead to incorrect model predictions.\n",
        "\n",
        "**Exercises:**\n",
        "1.  Try different NMPC tuning weights ($Q, R, S$) or prediction horizons ($N_p$).\n",
        "2.  Change the initial state of the plant. Does the ANN-NMPC still perform well?\n",
        "3.  If the ANN from Part 1 wasn't perfectly trained, or if you use a simpler/smaller ANN, how does it affect the closed-loop control performance?\n",
        "4.  (Advanced) Try to make one of the constraints very tight to see if the solver reports infeasibility or if performance degrades significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318606be",
      "metadata": {},
      "source": [
        "## Conclusion of the Tutorial\n",
        "\n",
        "This three-part tutorial demonstrated a complete workflow for:\n",
        "1.  Training a neural network model for system dynamics in PyTorch.\n",
        "2.  Exporting this model to the ONNX format.\n",
        "3.  Importing the ONNX model into CasADi as a symbolic function.\n",
        "4.  Creating a wrapper to handle data scaling/unscaling for the ONNX model within CasADi.\n",
        "5.  Using this CasADi-wrapped ONNX model as the predictive core of an NMPC controller.\n",
        "6.  Simulating the closed-loop ANN-NMPC system.\n",
        "\n",
        "This ONNX interchange pathway is powerful because it allows leveraging the strengths of specialized frameworks: PyTorch for flexible neural network training and CasADi for efficient, structured nonlinear programming and optimal control.\n",
        "\n",
        "While this example used a relatively simple FNN and system, the same principles apply to more complex neural network architectures and control problems, with the main challenges often being the robust training of the data-driven model and ensuring its reliable integration and differentiation within the NMPC solver."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
