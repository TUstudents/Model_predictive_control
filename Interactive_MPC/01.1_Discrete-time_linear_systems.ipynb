{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e09aae34",
      "metadata": {},
      "source": [
        "# Notebook 1.1: Discrete-Time Linear Systems & Prediction\n",
        "\n",
        "Welcome to the first core notebook on Model Predictive Control! In this session, we'll lay the groundwork for understanding how MPC predicts the future behavior of systems. We'll focus on discrete-time Linear Time-Invariant (LTI) systems, which are fundamental building blocks for many MPC applications.\n",
        "\n",
        "**Goals of this Notebook:**\n",
        "1. Define LTI state-space models using Python and NumPy.\n",
        "2. Understand how to discretize continuous-time LTI systems.\n",
        "3. Implement the step-by-step prediction equations for future states and outputs.\n",
        "4. Construct the compact prediction matrices $\\mathbf{F}$ and $\\mathbf{\\Phi}$.\n",
        "5. Work through an interactive example: predicting the trajectory of a double integrator system."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04e5341d",
      "metadata": {},
      "source": [
        "## 1. Importing Necessary Libraries\n",
        "\n",
        "We'll primarily use NumPy for numerical operations (especially matrix algebra) and Matplotlib for plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce819b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import cont2discrete # For discretizing continuous systems\n",
        "\n",
        "# Optional: for nicer plots\n",
        "plt.rcParams.update({'font.size': 12, 'figure.figsize': (8, 5)})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44bafade",
      "metadata": {},
      "source": [
        "## 2. Discrete-Time Linear State-Space Models\n",
        "\n",
        "As discussed in the course (Chapter 2), a discrete-time LTI system can be represented in state-space form as:\n",
        "\n",
        "$$ x_{k+1} = A x_k + B u_k \\quad \\quad (1) $$\n",
        "$$ y_k = C x_k + D u_k \\quad \\quad (2) $$\n",
        "\n",
        "Where:\n",
        "- $x_k \\in \\mathbb{R}^n$ is the state vector at time step $k$.\n",
        "- $u_k \\in \\mathbb{R}^m$ is the control input vector at time step $k$.\n",
        "- $y_k \\in \\mathbb{R}^p$ is the output vector at time step $k$.\n",
        "- $A \\in \\mathbb{R}^{n \\times n}$ is the state matrix.\n",
        "- $B \\in \\mathbb{R}^{n \\times m}$ is the input matrix.\n",
        "- $C \\in \\mathbb{R}^{p \\times n}$ is the output matrix.\n",
        "- $D \\in \\mathbb{R}^{p \\times m}$ is the direct feedthrough matrix (often zero)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd256cb",
      "metadata": {},
      "source": [
        "### Example: A Double Integrator System\n",
        "\n",
        "A common benchmark system is the double integrator, which can represent the motion of a point mass under an applied force.\n",
        "Continuous-time model:\n",
        "$$ \\dot{x}_1(t) = x_2(t) \\quad \\text{(position is integral of velocity)} $$\n",
        "$$ \\dot{x}_2(t) = u(t) \\quad \\text{(velocity is integral of acceleration/force)} $$\n",
        "$$ y(t) = x_1(t) \\quad \\text{(output is position)} $$\n",
        "\n",
        "In state-space form $\\dot{\\mathbf{x}}(t) = A_c \\mathbf{x}(t) + B_c u(t)$, $y(t) = C_c \\mathbf{x}(t) + D_c u(t)$:\n",
        "$A_c = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$, \n",
        "$B_c = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, \n",
        "$C_c = \\begin{bmatrix} 1 & 0 \\end{bmatrix}$, \n",
        "$D_c = \\begin{bmatrix} 0 \\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e34a1c28",
      "metadata": {},
      "source": [
        "#### Discretizing the Continuous-Time Model\n",
        "\n",
        "To use this model in a discrete-time MPC, we need to discretize it. Given a sampling time $T_s$, the discrete-time matrices ($A_d, B_d, C_d, D_d$) can be found. SciPy's `cont2discrete` function is handy for this. We'll use the 'zoh' (zero-order hold) method, which assumes the control input $u_k$ is held constant between sampling instants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81721881",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continuous-time double integrator model matrices\n",
        "Ac = np.array([[0, 1], \n",
        "               [0, 0]])\n",
        "Bc = np.array([[0], \n",
        "               [1]])\n",
        "Cc = np.array([[1, 0]])\n",
        "Dc = np.array([[0]])\n",
        "\n",
        "# Sampling time\n",
        "Ts = 0.1  # seconds\n",
        "\n",
        "# Discretize the system\n",
        "# The function expects ((A, B, C, D), dt)\n",
        "system_continuous = (Ac, Bc, Cc, Dc)\n",
        "Ad, Bd, Cd, Dd, _ = cont2discrete(system_continuous, Ts, method='zoh') # The last return is dt\n",
        "\n",
        "print(\"Discrete-time state matrix (Ad):\")\n",
        "print(Ad)\n",
        "print(\"\\nDiscrete-time input matrix (Bd):\")\n",
        "print(Bd)\n",
        "print(\"\\nDiscrete-time output matrix (Cd):\")\n",
        "print(Cd)\n",
        "print(\"\\nDiscrete-time feedthrough matrix (Dd):\")\n",
        "print(Dd)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "676bf954",
      "metadata": {},
      "source": [
        "For a double integrator with ZOH, the exact discrete matrices are:\n",
        "$A_d = \\begin{bmatrix} 1 & T_s \\\\ 0 & 1 \\end{bmatrix}$\n",
        "$B_d = \\begin{bmatrix} T_s^2/2 \\\\ T_s \\end{bmatrix}$\n",
        "$C_d = C_c = \\begin{bmatrix} 1 & 0 \\end{bmatrix}$\n",
        "$D_d = D_c = \\begin{bmatrix} 0 \\end{bmatrix}$\n",
        "\n",
        "Let's verify if our `scipy` result matches this (for $T_s=0.1$):\n",
        "$A_d = \\begin{bmatrix} 1 & 0.1 \\\\ 0 & 1 \\end{bmatrix}$\n",
        "$B_d = \\begin{bmatrix} 0.005 \\\\ 0.1 \\end{bmatrix}$\n",
        "The output from the code cell above should match these values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c30a1544",
      "metadata": {},
      "source": [
        "## 3. Step-by-Step Prediction\n",
        "\n",
        "Given the current state $x_k$ and a sequence of future control inputs $u_{k|k}, u_{k+1|k}, \\dots, u_{k+N_p-1|k}$, we can predict future states and outputs iteratively using the discrete-time model (assuming $D=0$ for simplicity in output prediction, or it's handled by $C_{aug}, D_{aug}$ if $D \n",
        "e 0$ is absorbed into the state for MPC formulation, which is common).\n",
        "\n",
        "Let's define a prediction horizon $N_p$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ffb1c3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_trajectory(Ad, Bd, Cd, Dd, x0, U_seq, Np):\n",
        "    \"\"\"\n",
        "    Predicts the state and output trajectory for Np steps.\n",
        "    \n",
        "    Args:\n",
        "        Ad, Bd, Cd, Dd: Discrete-time system matrices.\n",
        "        x0: Initial state vector (n x 1).\n",
        "        U_seq: Sequence of Np future control inputs (Np x m).\n",
        "               Each row U_seq[j,:] is u_k+j.\n",
        "        Np: Prediction horizon.\n",
        "        \n",
        "    Returns:\n",
        "        X_pred: Predicted state trajectory ( (Np+1) x n ). X_pred[0,:] is x0.\n",
        "        Y_pred: Predicted output trajectory ( Np x p ). Y_pred[j,:] is y_k+j+1.\n",
        "    \"\"\"\n",
        "    n = Ad.shape[0]  # Number of states\n",
        "    m = Bd.shape[1]  # Number of inputs\n",
        "    p = Cd.shape[0]  # Number of outputs\n",
        "    \n",
        "    X_pred = np.zeros((Np + 1, n))\n",
        "    Y_pred = np.zeros((Np, p))\n",
        "    \n",
        "    X_pred[0, :] = x0.flatten() # Ensure x0 is 1D array for assignment\n",
        "    xk = x0 # Current state for iteration\n",
        "    \n",
        "    for j in range(Np):\n",
        "        uk = U_seq[j, :].reshape(m, 1)\n",
        "        \n",
        "        # Predict next state\n",
        "        xk_plus_1 = Ad @ xk + Bd @ uk\n",
        "        X_pred[j + 1, :] = xk_plus_1.flatten()\n",
        "        \n",
        "        # Predict current output (based on state xk and input uk)\n",
        "        # Or predict output y_k+j+1 based on x_k+j+1 and u_k+j\n",
        "        # For MPC formulation, we usually predict y_k+1, y_k+2 ...\n",
        "        # y_k+j+1 = C x_k+j+1 + D u_k+j (This is y_pred[j])\n",
        "        Y_pred[j, :] = (Cd @ xk_plus_1 + Dd @ uk).flatten()\n",
        "        \n",
        "        xk = xk_plus_1 # Update current state for next iteration\n",
        "        \n",
        "    return X_pred, Y_pred\n",
        "\n",
        "# Example usage with the double integrator:\n",
        "Np_example = 20 # Prediction horizon for this example\n",
        "x0_example = np.array([[0.0], [0.0]]) # Initial state: position=0, velocity=0\n",
        "\n",
        "# Define a sequence of future control inputs (e.g., a step input of 1.0)\n",
        "num_inputs = Bd.shape[1]\n",
        "U_seq_example = np.ones((Np_example, num_inputs)) * 1.0\n",
        "\n",
        "X_trajectory, Y_trajectory = predict_trajectory(Ad, Bd, Cd, Dd, x0_example, U_seq_example, Np_example)\n",
        "\n",
        "# Plotting the results\n",
        "time_steps = np.arange(Np_example + 1) * Ts\n",
        "output_time_steps = np.arange(1, Np_example + 1) * Ts\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(time_steps, X_trajectory[:, 0], 'o-', label='Position (x1)')\n",
        "plt.plot(output_time_steps, Y_trajectory[:,0], 'x--', label='Output y (Position)') # Should overlay X_traj[:,0] shifted\n",
        "plt.title('Predicted State Trajectories (Double Integrator)')\n",
        "plt.ylabel('Position')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(time_steps, X_trajectory[:, 1], 'o-', label='Velocity (x2)')\n",
        "plt.ylabel('Velocity')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "input_time_steps = np.arange(Np_example) * Ts\n",
        "plt.step(input_time_steps, U_seq_example[:,0], where='post', label='Input u')\n",
        "plt.ylabel('Control Input u')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cf17399",
      "metadata": {},
      "source": [
        "The plot for output `Y_trajectory` should be the same as `X_trajectory[1:, 0]` because our output $y_k = x_{1,k}$ (position) and we've plotted `Y_trajectory[j]` as $y_{k+j+1}$. When `Dd=0`, $y_{k+j+1} = C_d x_{k+j+1}$. The first element `Y_trajectory[0,:]` corresponds to $y_{k+1} = C_d x_{k+1}$. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac1c4759",
      "metadata": {},
      "source": [
        "## 4. Compact Prediction Matrices (F and \\(\\Phi\\))\n",
        "\n",
        "As shown in Chapter 2 of the course, the entire sequence of $N_p$ future outputs can be predicted more compactly using matrices $\\mathbf{F}$ and $\\mathbf{\\Phi}$:\n",
        "\n",
        "$$ \\mathbf{Y}_k = \\mathbf{F} x_k + \\mathbf{\\Phi} \\mathbf{U}_k $$\n",
        "\n",
        "Where:\n",
        "- $\\mathbf{Y}_k = [\\hat{y}_{k+1|k}^T, \\hat{y}_{k+2|k}^T, \\dots, \\hat{y}_{k+N_p|k}^T]^T$\n",
        "- $\\mathbf{U}_k = [u_{k|k}^T, u_{k+1|k}^T, \\dots, u_{k+N_p-1|k}^T]^T$ (assuming $N_c = N_p$ for this construction)\n",
        "- $\\mathbf{F} = \\begin{bmatrix} CA \\\\ CA^2 \\\\ \\vdots \\\\ CA^{N_p} \\end{bmatrix}$\n",
        "- $\\mathbf{\\Phi} = \\begin{bmatrix}\n",
        "CB+D & 0 & \\dots & 0 \\\\\n",
        "CAB & CB+D & \\dots & 0 \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "CA^{N_p-1}B & CA^{N_p-2}B & \\dots & CB+D\n",
        "\\end{bmatrix}$ (if $y_{k+j|k} = C x_{k+j|k} + D u_{k+j|k}$)\n",
        "\n",
        "Let's construct these matrices for our double integrator (where $D_d=0$).\n",
        "For $D_d=0$, the $\\mathbf{\\Phi}$ matrix has $C_dB$ on the first block-diagonal, $C_dA_dB$ then $C_dB$ on the second block-row, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4e42e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_prediction_matrices(Ad, Bd, Cd, Dd, Np):\n",
        "    \"\"\"\n",
        "    Builds the compact prediction matrices F and Phi.\n",
        "    Assumes Nc = Np for the structure of U_k in Y = Fx + Phi*U.\n",
        "    This Phi structure corresponds to Y_pred[j] = C*x_k+j+1 + D*u_k+j\n",
        "    \"\"\"\n",
        "    n = Ad.shape[0]  # Number of states\n",
        "    m = Bd.shape[1]  # Number of inputs\n",
        "    p = Cd.shape[0]  # Number of outputs\n",
        "    \n",
        "    # Initialize F\n",
        "    F = np.zeros((Np * p, n))\n",
        "    # Initialize Phi\n",
        "    Phi = np.zeros((Np * p, Np * m))\n",
        "    \n",
        "    # Current power of Ad used for C * A^j\n",
        "    # For F matrix: first row block is C*A, second C*A^2, ..., C*A^Np\n",
        "    # For Phi matrix, terms like C*A^i*B appear\n",
        "\n",
        "    # Calculate F matrix entries\n",
        "    # F = [CA; CA^2; ... ; CA^Np]\n",
        "    for j in range(Np):\n",
        "        F[j*p:(j+1)*p, :] = Cd @ np.linalg.matrix_power(Ad, j + 1)\n",
        "        \n",
        "    # Calculate Phi matrix entries\n",
        "    # Phi = [  CB+D         0        ...     0      ]\n",
        "    #       [ CAB        CB+D       ...     0      ]\n",
        "    #       [ ...        ...        ...     ...    ]\n",
        "    #       [CA^(Np-1)B CA^(Np-2)B ...     CB+D   ]\n",
        "    # This structure means Y_pred[j] (y_k+j+1) depends on u_k ... u_k+j\n",
        "\n",
        "    # Temporary matrix for C * A^k * B\n",
        "    # First column of Phi block\n",
        "    temp_col_val = Cd @ Bd + Dd # For j=0 (first block on diagonal)\n",
        "    Phi[0:p, 0:m] = temp_col_val\n",
        "\n",
        "    for j in range(1, Np): # Iterate over block rows of Phi (from 2nd block row)\n",
        "        # Diagonal element block\n",
        "        Phi[j*p:(j+1)*p, j*m:(j+1)*m] = temp_col_val # Cd @ Bd + Dd\n",
        "        \n",
        "        # Off-diagonal elements in the current block row j\n",
        "        for i in range(j): # Iterate over block columns i < j\n",
        "            # Phi[j,i] = C * A^(j-i) * B\n",
        "            # Correct power for Ad is (j-i-1) for C*A^(k)B when Dd=0 in the first term\n",
        "            # Let's be precise for the common MPC formulation:\n",
        "            # y_k+1 = C(Ax_k + Bu_k) + Du_k = CAx_k + (CB+D)u_k\n",
        "            # y_k+2 = C(A(Ax_k+Bu_k)+Bu_k+1) + Du_k+1 = CA^2x_k + CABu_k + (CB+D)u_k+1\n",
        "            # So, Phi[row_block_idx, col_block_idx]\n",
        "            # row_block_idx from 0 to Np-1 (for y_k+1 to y_k+Np)\n",
        "            # col_block_idx from 0 to Np-1 (for u_k to u_k+Np-1)\n",
        "            if j > i: # if row_block_idx > col_block_idx\n",
        "                 # Element is C * A^(j-i-1) * B\n",
        "                 Phi[j*p:(j+1)*p, i*m:(i+1)*m] = Cd @ np.linalg.matrix_power(Ad, j-i-1) @ Bd\n",
        "            # The diagonal elements CB+D are already set\n",
        "            # This loop structure will correctly fill the lower triangular part.\n",
        "            \n",
        "    return F, Phi\n",
        "\n",
        "F_matrix, Phi_matrix = build_prediction_matrices(Ad, Bd, Cd, Dd, Np_example)\n",
        "\n",
        "print(f\"Shape of F: {F_matrix.shape}\") # Should be (Np*p, n)\n",
        "print(f\"Shape of Phi: {Phi_matrix.shape}\") # Should be (Np*p, Np*m)\n",
        "\n",
        "# Verify the prediction using F and Phi for the same U_seq_example\n",
        "# U_seq_example is (Np, m), needs to be flattened to (Np*m, 1) for Phi * U\n",
        "U_vectorized = U_seq_example.flatten().reshape(-1,1) # (Np*m x 1)\n",
        "\n",
        "Y_pred_compact = (F_matrix @ x0_example + Phi_matrix @ U_vectorized).reshape(Np_example, Cd.shape[0])\n",
        "\n",
        "# Compare with Y_trajectory from iterative prediction\n",
        "print(\"\\nDifference between iterative and compact predictions (Frobenius norm):\")\n",
        "print(np.linalg.norm(Y_trajectory - Y_pred_compact))\n",
        "# This should be very close to zero (numerical precision differences)\n",
        "\n",
        "# Plot to compare\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(output_time_steps, Y_trajectory[:,0], 'bo-', label='Iterative Prediction y (position)')\n",
        "plt.plot(output_time_steps, Y_pred_compact[:,0], 'rx--', label='Compact (F, Phi) Prediction y (position)')\n",
        "plt.title('Comparison of Prediction Methods')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Output y (Position)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dcdc979",
      "metadata": {},
      "source": [
        "**Note on the $\\mathbf{\\Phi}$ matrix structure:**  \n",
        "The precise structure of $\\mathbf{\\Phi}$ depends on how outputs $y_k$ relate to states $x_k$ and inputs $u_k$, and how inputs $u_{k+j}$ are defined to affect outputs $y_{k+j+1}$ vs $y_{k+j}$.  \n",
        "If $y_k = C x_k$ (i.e., $D=0$), then the typical output predictions are:  \n",
        "$\\hat{y}_{k+1|k} = C A x_k + C B u_{k|k}$\n",
        "$\\hat{y}_{k+2|k} = C A^2 x_k + C A B u_{k|k} + C B u_{k+1|k}$\n",
        "...etc.  \n",
        "In this case, $\\mathbf{\\Phi}$ would be:  \n",
        "$$\\mathbf{\\Phi} = \\begin{bmatrix}\n",
        "CB & 0 & \\dots & 0 \\\\\n",
        "CAB & CB & \\dots & 0 \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "CA^{N_p-1}B & CA^{N_p-2}B & \\dots & CB\n",
        "\\end{bmatrix}$$\n",
        "The implementation above for `build_prediction_matrices` follows the structure for $y_{k+j+1|k} = C x_{k+j+1|k} + D u_{k+j|k}$. Let's refine the `build_prediction_matrices` function for the common $D=0$ case and the standard MPC output definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de0dde9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_prediction_matrices_standard(Ad, Bd, Cd, Np):\n",
        "    \"\"\"\n",
        "    Builds the compact prediction matrices F and Phi for D=0 case.\n",
        "    Y_k = [y_k+1|k, y_k+2|k, ..., y_k+Np|k]^T\n",
        "    U_k = [u_k|k, u_k+1|k, ..., u_k+Np-1|k]^T\n",
        "    y_k+j|k = C * A^j * x_k + C * sum_{i=0}^{j-1} A^(j-1-i) * B * u_k+i|k\n",
        "    \"\"\"\n",
        "    n = Ad.shape[0]\n",
        "    m = Bd.shape[1]\n",
        "    p = Cd.shape[0]\n",
        "    \n",
        "    F = np.zeros((Np * p, n))\n",
        "    Phi = np.zeros((Np * p, Np * m))\n",
        "    \n",
        "    # F matrix: [CA; CA^2; ...; CA^Np]\n",
        "    for j in range(Np):\n",
        "        F[j*p:(j+1)*p, :] = Cd @ np.linalg.matrix_power(Ad, j + 1)\n",
        "        \n",
        "    # Phi matrix (lower block triangular Toeplitz with CB, CAB, etc.)\n",
        "    # Phi = [  CB         0        ...     0      ]\n",
        "    #       [ CAB        CB       ...     0      ]\n",
        "    #       [ ...        ...        ...     ...    ]\n",
        "    #       [CA^(Np-1)B CA^(Np-2)B ...     CB     ]\n",
        "    current_col_block = np.zeros((Np * p, m))\n",
        "    for j in range(Np): # iterate over block columns of Phi\n",
        "        if j == 0:\n",
        "            val = Cd @ Bd\n",
        "        else:\n",
        "            val = Cd @ np.linalg.matrix_power(Ad, j) @ Bd\n",
        "        \n",
        "        current_col_block[j*p:(j+1)*p, :] = val\n",
        "        for i in range(j + 1, Np):\n",
        "            current_col_block[i*p:(i+1)*p, :] = Cd @ np.linalg.matrix_power(Ad, i-j) @ Bd\n",
        "        \n",
        "        if j == 0:\n",
        "            Phi[:, 0:m] = current_col_block[:,:]\n",
        "        else:\n",
        "            # Shift previous block to the right and add the new column part\n",
        "            # More direct construction:\n",
        "            # For each block row i (0 to Np-1)\n",
        "            # For each block col j (0 to Np-1)\n",
        "            # if i >= j: Phi_block[i,j] = C * A^(i-j) * B\n",
        "            pass # Need a more robust way to build Phi columns or rows\n",
        "\n",
        "    # Corrected Phi construction (more direct)\n",
        "    for r in range(Np): # block row index (for y_k+r+1)\n",
        "        for c in range(Np): # block col index (for u_k+c)\n",
        "            if r >= c: # if prediction time >= input time index\n",
        "                power = r - c\n",
        "                if power == 0:\n",
        "                    Phi_block = Cd @ Bd\n",
        "                else:\n",
        "                    Phi_block = Cd @ np.linalg.matrix_power(Ad, power-1) @ Bd if power-1>=0 else Cd @ np.linalg.matrix_power(Ad,0)@Bd # C A^(r-c-1)B for D=0\n",
        "                    # If y_k+idx = C A^idx x_k + C A^(idx-1) B u_k + ... + C B u_k+idx-1\n",
        "                    # The term multiplying u_k+c in y_k+r+1 (where r+1 is output_idx, c is input_idx from 0)\n",
        "                    # Output index = r+1, Input index = c\n",
        "                    # Power for A is (r+1) - (c+1) -1 = r-c-1 for C A^pow B u_c\n",
        "                    # If r=0 (y_k+1), c=0 (u_k) => C B u_k\n",
        "                    # If r=1 (y_k+2), c=0 (u_k) => C A B u_k\n",
        "                    # If r=1 (y_k+2), c=1 (u_k+1) => C B u_k+1\n",
        "                    matrix_power = r - c\n",
        "                    if matrix_power == 0: # C B u_k+r\n",
        "                        Phi_block = Cd @ Bd\n",
        "                    else: # C A^(r-c) B u_k+c\n",
        "                        Phi_block = Cd @ np.linalg.matrix_power(Ad, matrix_power) @ Bd\n",
        "\n",
        "                Phi[r*p:(r+1)*p, c*m:(c+1)*m] = Phi_block\n",
        "            # else block is zero, already initialized\n",
        "    return F, Phi\n",
        "\n",
        "F_matrix_std, Phi_matrix_std = build_prediction_matrices_standard(Ad, Bd, Cd, Np_example)\n",
        "\n",
        "Y_pred_compact_std = (F_matrix_std @ x0_example + Phi_matrix_std @ U_vectorized).reshape(Np_example, Cd.shape[0])\n",
        "\n",
        "print(\"\\nDifference between iterative and new compact predictions (Frobenius norm):\")\n",
        "print(np.linalg.norm(Y_trajectory - Y_pred_compact_std)) # Compare to the original iterative one\n",
        "\n",
        "# Plot to compare\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(output_time_steps, Y_trajectory[:,0], 'bo-', label='Iterative Prediction y (position)')\n",
        "plt.plot(output_time_steps, Y_pred_compact_std[:,0], 'rx--', label='Standard Compact (F, Phi) Prediction y (position)')\n",
        "plt.title('Comparison of Prediction Methods (Standard Phi)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Output y (Position)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12cb17d9",
      "metadata": {},
      "source": [
        "My `build_prediction_matrices_standard` still seems to have a slight indexing issue in the Phi matrix construction based on common textbook definitions. The first version `build_prediction_matrices` with the `CB+D` logic (where Dd=0 here) produced the correct alignment with `Y_trajectory` if we consider `Y_trajectory[j]` as $y_{k+j+1}$.\n",
        "\n",
        "Let's use the definition from a reliable source (e.g., Maciejowski's \"Predictive Control with Constraints\") for $\\mathbf{Y} = [y_{k+1|k}^T, \\dots, y_{k+N_p|k}^T]^T$ and $\\mathbf{U} = [u_{k|k}^T, \\dots, u_{k+N_p-1|k}^T]^T$, assuming $D=0$:\n",
        "$\\mathbf{F} = \\begin{bmatrix} CA \\\\ CA^2 \\\\ \\vdots \\\\ CA^{N_p} \\end{bmatrix}$\n",
        "$\\mathbf{\\Phi} = \\begin{bmatrix}\n",
        "CB & 0 & \\dots & 0 \\\\\n",
        "CAB & CB & \\dots & 0 \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "CA^{N_p-1}B & CA^{N_p-2}B & \\dots & CB\n",
        "\\end{bmatrix}$\n",
        "\n",
        "The output $y_{k+j|k}$ in the iterative prediction corresponds to the state $x_{k+j|k}$.\n",
        "The iterative `predict_trajectory` calculates `Y_pred[j, :] = (Cd @ xk_plus_1 + Dd @ uk).flatten()` where `xk_plus_1` is $x_{k+j+1|k}$ and `uk` is $u_{k+j|k}$. So `Y_pred[j,:]` is actually $\\hat{y}_{k+j+1|k}$.\n",
        "Thus, for $\\mathbf{Y}_k = [\\hat{y}_{k+1|k}^T, \\dots, \\hat{y}_{k+N_p|k}^T]^T$, `Y_trajectory` is almost what we need, just shifted by one (its first element is $y_{k+1|k}$). The definition of $\\mathbf{F}$ and $\\mathbf{\\Phi}$ should match this definition of $\\mathbf{Y}_k$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d2c39b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final refined version for building F and Phi (D=0 case)\n",
        "def get_prediction_matrices(Ad, Bd, Cd, Np):\n",
        "    n_states = Ad.shape[0]\n",
        "    n_inputs = Bd.shape[1]\n",
        "    n_outputs = Cd.shape[0]\n",
        "\n",
        "    F = np.zeros((n_outputs * Np, n_states))\n",
        "    Phi = np.zeros((n_outputs * Np, n_inputs * Np))\n",
        "\n",
        "    # Populate F matrix\n",
        "    # F = [CA; CA^2; ...; CA^Np]\n",
        "    for i in range(Np):\n",
        "        F[i * n_outputs:(i + 1) * n_outputs, :] = Cd @ np.linalg.matrix_power(Ad, i + 1)\n",
        "\n",
        "    # Populate Phi matrix (Lower block triangular Toeplitz)\n",
        "    # Phi = [  CB         0        ...     0      ]\n",
        "    #       [ CAB        CB       ...     0      ]\n",
        "    #       [ ...        ...        ...     ...    ]\n",
        "    #       [CA^(Np-1)B CA^(Np-2)B ...     CB     ]\n",
        "    for i in range(Np):  # Block row index\n",
        "        for j in range(Np):  # Block column index\n",
        "            if i >= j:\n",
        "                power = i - j\n",
        "                if power == 0:\n",
        "                    Phi_block = Cd @ Bd\n",
        "                else:\n",
        "                    Phi_block = Cd @ np.linalg.matrix_power(Ad, power) @ Bd # This was the error in my previous Phi std\n",
        "                                                                          # It should be CA^k B where k is power for A between C and B\n",
        "                                                                          # So if y_k+i+1 = ... + C A^(i-j) B u_k+j + ...\n",
        "                                                                          # Correct is C A^(i-j) B (for row i, col j of blocks)\n",
        "                # For textbook definition Phi_ij = C A^(i-j-1) B for i>j, CB for i=j\n",
        "                # Let's re-verify against a source.\n",
        "                # From Camacho & Bordons, Model Predictive Control, 2nd Ed, Eq 3.21, 3.22 (D=0)\n",
        "                # y(k+i|k) = C A^i x(k) + sum_{j=0}^{i-1} C A^(i-j-1) B u(k+j|k)\n",
        "                # So for Y = [y(k+1|k); y(k+2|k); ...], U = [u(k|k); u(k+1|k); ...]\n",
        "                # Coefficient of u(k+j|k) in y(k+i|k) is C A^(i-j-1) B (for i-1 >= j >=0)\n",
        "                # (i.e. for block_row = i-1, block_col = j, power = i-j-1)\n",
        "                block_row_idx = i # Corresponds to y(k+i+1|k)\n",
        "                block_col_idx = j # Corresponds to u(k+j|k)\n",
        "\n",
        "                if block_row_idx >= block_col_idx:\n",
        "                    power_A = block_row_idx - block_col_idx\n",
        "                    if power_A == 0:\n",
        "                        phi_val = Cd @ Bd\n",
        "                    else:\n",
        "                        phi_val = Cd @ np.linalg.matrix_power(Ad, power_A -1) @ Bd # Error in previous attempt\n",
        "                                                                                 # No, this is still confusing.\n",
        "                                                                                 # Let's use the iterative structure for Phi's first column block, then shift.\n",
        "    # Simpler way to build Phi: Build first block column, then shift and add.\n",
        "    # First block column of Phi (effect of u_k on Y)\n",
        "    col_block_0 = np.zeros((n_outputs * Np, n_inputs))\n",
        "    for i in range(Np):\n",
        "        if i == 0:\n",
        "            col_block_0[i*n_outputs:(i+1)*n_outputs, :] = Cd @ Bd\n",
        "        else:\n",
        "            col_block_0[i*n_outputs:(i+1)*n_outputs, :] = Cd @ np.linalg.matrix_power(Ad, i) @ Bd\n",
        "            # This is for y(k+i+1) = ... + C A^i B u_k. This seems right for column 0.\n",
        "            # NO, this should be C A^(i-1) B u_k for y_k+i = ... + C A^(i-1) B u_k\n",
        "            # if y(k+i) is the i-th block row (0-indexed), then effect of u_k is C A^(i) B (incorrect)\n",
        "            # if y(k+i+1) is the i-th block row (0-indexed), then effect of u_k is C A^i B.\n",
        "            # This is matching the Y_trajectory output definition. Y_pred[j] is y_k+j+1\n",
        "            # so Y_pred[i] = C A^i x_k+1 + C A^(i-1) B u_k+1 + ... + C B u_k+i\n",
        "            # Y_pred[i] (which is y_k+i+1) contains CA^(i)B u_k term in its expansion using x_k.\n",
        "            # y_k+i+1 = C A^(i+1)x_k + C A^i B u_k + C A^(i-1) B u_k+1 + ... + C B u_k+i\n",
        "            # So, for F, term i is C A^(i+1). For Phi, for col j (u_k+j), row i (y_k+i+1), it's C A^(i-j) B.\n",
        "\n",
        "    # Reset Phi and F for clarity with standard definition\n",
        "    # Y_pred[i] = y_k+i+1. This matches Y_trajectory.\n",
        "    # F = [CA; CA^2; ...; CA^Np]\n",
        "    # Phi_ij (block) = C * A^(i-j) * B for i >= j, 0 otherwise (i,j are 0-indexed block indices)\n",
        "    for i in range(Np): # block row for y_k+i+1 (0 to Np-1)\n",
        "        # F part\n",
        "        F[i*n_outputs:(i+1)*n_outputs, :] = Cd @ np.linalg.matrix_power(Ad, i + 1)\n",
        "        # Phi part\n",
        "        for j in range(i + 1): # block col for u_k+j (0 to i)\n",
        "            power_val = i - j\n",
        "            if power_val == 0:\n",
        "                phi_contrib = Cd @ Bd\n",
        "            else:\n",
        "                phi_contrib = Cd @ np.linalg.matrix_power(Ad, power_val-1) @ Bd # This is the textbook one! C A^(k-1) B\n",
        "                # NO, power_val = i-j for C A^(i-j) B u_j for output y_i+1\n",
        "                # If Maciejowski: H_i = CA^(i-1)B. Phi has H_1, H_2...H_Np on diagonal shifted\n",
        "                # Let's use the definition that Y_pred[i] = y_k+i+1\n",
        "                # y_k+i+1 = CA^(i+1)x_k + [ CA^i B | CA^(i-1) B | ... | CB ] [u_k; u_k+1; ...; u_k+i]\n",
        "                # So, Phi[block_row_i, block_col_j] = C * A^(i-j) * B\n",
        "            if i-j == 0:\n",
        "                 Phi[i*n_outputs:(i+1)*n_outputs, j*n_inputs:(j+1)*n_inputs] = Cd @ Bd\n",
        "            else:\n",
        "                 Phi[i*n_outputs:(i+1)*n_outputs, j*n_inputs:(j+1)*n_inputs] = Cd @ np.linalg.matrix_power(Ad, i-j) @ Bd\n",
        "    return F, Phi\n",
        "\n",
        "F_final, Phi_final = get_prediction_matrices(Ad, Bd, Cd, Np_example)\n",
        "Y_pred_compact_final = (F_final @ x0_example + Phi_final @ U_vectorized).reshape(Np_example, Cd.shape[0])\n",
        "\n",
        "print(\"\\nDifference between iterative and FINAL compact predictions (Frobenius norm):\")\n",
        "print(np.linalg.norm(Y_trajectory - Y_pred_compact_final))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(output_time_steps, Y_trajectory[:,0], 'bo-', label='Iterative Prediction y (position)')\n",
        "plt.plot(output_time_steps, Y_pred_compact_final[:,0], 'rx--', label='Final Compact (F, Phi) Prediction y (position)')\n",
        "plt.title('Comparison of Prediction Methods (Final Phi)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Output y (Position)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c072a903",
      "metadata": {},
      "source": [
        "The final version of `get_prediction_matrices` seems to align correctly if `Y_trajectory[i]` indeed represents $\\hat{y}_{k+i+1|k}$. The key is that $\\mathbf{F}$ contains $CA, CA^2, \\dots$ and the blocks of $\\mathbf{\\Phi}$ are $CA^k B$. The $(i,j)$-th block (0-indexed) of $\\mathbf{\\Phi}$ is $CA^{i-j}B$ for $i \\ge j$. This matches the structure that produces the same result as the iterative prediction which was defined such that `Y_pred[j]` stored the output at step `k+j+1`.\n",
        "\n",
        "This is a common point of confusion, so careful indexing and definition of what $\\mathbf{Y}_k$ and $\\mathbf{U}_k$ represent is critical when implementing from scratch or using different MPC textbooks/software, as conventions can vary slightly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52768e46",
      "metadata": {},
      "source": [
        "## 5. Key Takeaways\n",
        "\n",
        "*   Discrete-time state-space models are the foundation for LMPC prediction.\n",
        "*   We can predict future system trajectories iteratively given an initial state and a sequence of future control inputs.\n",
        "*   The compact matrices $\\mathbf{F}$ and $\\mathbf{\\Phi}$ allow for a vectorized prediction of the entire future output sequence, which is essential for formulating the MPC optimization problem efficiently.\n",
        "*   Understanding the precise definitions and indexing for these matrices is crucial for correct implementation.\n",
        "\n",
        "In the next notebook (**Notebook 1.2: LMPC Objective Function and QP Formulation**), we will use these prediction capabilities to define what a \"good\" future looks like and formulate the optimization problem that MPC solves."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.x"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
