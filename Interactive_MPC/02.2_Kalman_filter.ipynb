{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.x"
    },
    "toc": {
        "base_numbering": 1,
        "nav_menu": {},
        "number_sections": true,
        "sideBar": true,
        "skip_h1_title": false,
        "title_cell": "Table of Contents",
        "title_sidebar": "Contents",
        "toc_cell": false,
        "toc_position": {},
        "toc_section_display": true,
        "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 2.2: The Kalman Filter for LMPC â€“ Estimating States from Noisy Data\n",
        "\n",
        "In previous notebooks, our LMPC implementations assumed that the full state vector $x_k$ of the system was perfectly known at each time step. In reality, this is rarely the case. We typically only have access to noisy measurements of some output variables $y_k$, and the system itself is subject to unmeasured process disturbances.\n",
        "\n",
        "The **Kalman Filter (KF)** is an optimal recursive algorithm for estimating the internal states of a linear dynamic system from a series of noisy measurements. It plays a crucial role in enabling practical Model Predictive Control by providing the necessary state estimates.\n",
        "\n",
        "**Goals of this Notebook:**\n",
        "1. Understand the discrete-time Kalman Filter equations (predict and update steps).\n",
        "2. Implement a Kalman Filter in Python.\n",
        "3. Discuss the tuning of the process noise covariance ($Q_K$) and measurement noise covariance ($R_K$) matrices.\n",
        "4. Integrate the Kalman Filter with the LMPC controller (from Notebook 1.3/1.4) to achieve output feedback control.\n",
        "5. Simulate the LMPC with KF on the double integrator system, visualizing true states, estimated states, and closed-loop performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importing Libraries and Re-using Code\n",
        "\n",
        "We'll use NumPy, Matplotlib, SciPy for system definitions, and CVXPY for the MPC's QP solver. We'll adapt the LMPC setup from previous notebooks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import cont2discrete\n",
        "import cvxpy as cp\n",
        "\n",
        "# Optional: for nicer plots\n",
        "plt.rcParams.update({'font.size': 12, 'figure.figsize': (12, 9)})\n",
        "\n",
        "# --- System Definition (Double Integrator from previous notebooks) ---\n",
        "Ac = np.array([[0, 1], [0, 0]])\n",
        "Bc = np.array([[0], [1]])\n",
        "Cc = np.array([[1, 0]]) # Output is position\n",
        "Dc = np.array([[0]])\n",
        "Ts = 0.1\n",
        "Ad, Bd, Cd, Dd, _ = cont2discrete((Ac, Bc, Cc, Dc), Ts, method='zoh')\n",
        "n_states = Ad.shape[0]\n",
        "n_inputs = Bd.shape[1]\n",
        "n_outputs = Cd.shape[0]\n",
        "\n",
        "# --- Prediction Matrices Function (from Notebook 1.1) ---\n",
        "def get_prediction_matrices(Ad_sys, Bd_sys, Cd_sys, Np_horizon):\n",
        "    n_s, n_i, n_o = Ad_sys.shape[0], Bd_sys.shape[1], Cd_sys.shape[0]\n",
        "    F = np.zeros((n_o * Np_horizon, n_s))\n",
        "    Phi = np.zeros((n_o * Np_horizon, n_i * Np_horizon))\n",
        "    for i in range(Np_horizon):\n",
        "        F[i*n_o:(i+1)*n_o, :] = Cd_sys @ np.linalg.matrix_power(Ad_sys, i + 1)\n",
        "        for j in range(i + 1):\n",
        "            if i-j == 0:\n",
        "                 Phi[i*n_o:(i+1)*n_o, j*n_i:(j+1)*n_i] = Cd_sys @ Bd_sys\n",
        "            else:\n",
        "                 Phi[i*n_o:(i+1)*n_o, j*n_i:(j+1)*n_i] = \\\n",
        "                    Cd_sys @ np.linalg.matrix_power(Ad_sys, i-j) @ Bd_sys\n",
        "    return F, Phi\n",
        "\n",
        "# --- QP Components Builder (from Notebook 1.4, simplified for clarity here) ---\n",
        "def build_qp_components_basic(F_mat, Phi_mat, Q_val, R_val, S_val, Np_h, m_ins, p_outs):\n",
        "    Q_matrix_s = Q_val * np.eye(p_outs); R_matrix_s = R_val * np.eye(m_ins); S_matrix_s = S_val * np.eye(m_ins)\n",
        "    Q_bar_s = np.kron(np.eye(Np_h), Q_matrix_s); R_bar_s = np.kron(np.eye(Np_h), R_matrix_s); S_bar_s = np.kron(np.eye(Np_h), S_matrix_s)\n",
        "    T_diff_s = np.eye(Np_h * m_ins) - np.eye(Np_h * m_ins, k=-m_ins) # Efficient way for T_diff\n",
        "    T_diff_s[0:m_ins, 0:m_ins] = np.eye(m_ins) # First block of DeltaU is U_k - U_prev\n",
        "    # To be precise about T_diff for U_k - U_k-1, the first row block of T_diff would be [I 0 ... 0]\n",
        "    # and U_prev_stacked has u_k-1 in first block. This is simpler: \n",
        "    # DeltaU_0 = U_0 - u_prev ; DeltaU_i = U_i - U_i-1 for i>0\n",
        "    # Create T_prime such that T_prime @ [u_prev; U_k] = Delta_U_k\n",
        "    # Or, use T_diff as defined in 1.2, and subtract U_prev_stacked (vector with u_prev at top)\n",
        "    # For build_qp_components in 1.4, we had explicit T_diff and U_prev_stacked creation.\n",
        "    # Let's reuse that structure for consistency.\n",
        "    T_diff_s_orig = np.zeros((Np_h * m_ins, Np_h * m_ins))\n",
        "    for i in range(Np_h):\n",
        "        T_diff_s_orig[i*m_ins:(i+1)*m_ins, i*m_ins:(i+1)*m_ins] = np.eye(m_ins)\n",
        "        if i > 0:\n",
        "            T_diff_s_orig[i*m_ins:(i+1)*m_ins, (i-1)*m_ins:i*m_ins] = -np.eye(m_ins)\n",
        "\n",
        "    H_qp_s = 2 * (Phi_mat.T @ Q_bar_s @ Phi_mat + R_bar_s + T_diff_s_orig.T @ S_bar_s @ T_diff_s_orig)\n",
        "    \n",
        "    def compute_f_qp_inner(xk_curr, R_traj_v, u_prev_curr):\n",
        "        U_prev_stacked_s = np.zeros((Np_h * m_ins, 1))\n",
        "        U_prev_stacked_s[0:m_ins, 0] = u_prev_curr.flatten()\n",
        "        error_term_Fx_R_s = F_mat @ xk_curr - R_traj_v\n",
        "        f_qp_s = 2 * (Phi_mat.T @ Q_bar_s @ error_term_Fx_R_s - T_diff_s_orig.T @ S_bar_s @ U_prev_stacked_s)\n",
        "        return f_qp_s\n",
        "    return H_qp_s, compute_f_qp_inner, T_diff_s_orig # Return T_diff for constraints\n",
        "\n",
        "# MPC Parameters (from Notebook 1.4)\n",
        "Np = 20; Qw = 100.0; Rw = 0.1; Sw = 1.0\n",
        "F_mpc, Phi_mpc = get_prediction_matrices(Ad, Bd, Cd, Np)\n",
        "H_qp_mpc, compute_f_qp_mpc_func, T_diff_mpc = \\\n",
        "    build_qp_components_basic(F_mpc, Phi_mpc, Qw, Rw, Sw, Np, n_inputs, n_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. The Kalman Filter Algorithm\n",
        "\n",
        "The system with noise is described by:\n",
        "$$ x_{k+1} = A x_k + B u_k + G w_k \\quad (w_k \\sim \\mathcal{N}(0, Q_K)) $$\n",
        "$$ y_{m,k} = C x_k + D u_k + v_k \\quad (v_k \\sim \\mathcal{N}(0, R_K)) $$\n",
        "\n",
        "The Kalman Filter operates in two steps:\n",
        "\n",
        "**1. Time Update (Prediction):**\n",
        "   $\\hat{x}_{k|k-1} = A \\hat{x}_{k-1|k-1} + B u_{k-1}$ (Predict state)\n",
        "   $P_{k|k-1} = A P_{k-1|k-1} A^T + G Q_K G^T$ (Predict error covariance)\n",
        "\n",
        "**2. Measurement Update (Correction):**\n",
        "   $K_k = P_{k|k-1} C^T (C P_{k|k-1} C^T + R_K)^{-1}$ (Compute Kalman Gain)\n",
        "   $\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k (y_{m,k} - (C \\hat{x}_{k|k-1} + D u_k))$ (Update state estimate)\n",
        "   $P_{k|k} = (I - K_k C) P_{k|k-1}$ (Update error covariance)\n",
        "\n",
        "Here, $G$ is the process noise input matrix. If process noise is assumed to affect each state directly, $G$ can be $I$ (identity matrix) or chosen based on knowledge of how disturbances enter the system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class KalmanFilter:\n",
        "    def __init__(self, Ad, Bd, Cd, Dd, G_mat, Qk_mat, Rk_mat, x_hat0, P0):\n",
        "        self.Ad = Ad\n",
        "        self.Bd = Bd\n",
        "        self.Cd = Cd\n",
        "        self.Dd = Dd\n",
        "        self.G = G_mat # Process noise input matrix\n",
        "        self.Qk = Qk_mat # Process noise covariance\n",
        "        self.Rk = Rk_mat # Measurement noise covariance\n",
        "        \n",
        "        self.x_hat = x_hat0 # Current state estimate (a posteriori x_k|k)\n",
        "        self.P = P0       # Current error covariance (a posteriori P_k|k)\n",
        "        \n",
        "        self.n_states = Ad.shape[0]\n",
        "\n",
        "    def predict(self, uk_minus_1):\n",
        "        # Time Update (Prediction)\n",
        "        # uk_minus_1 is the input applied at the previous step that led to current state x_k\n",
        "        self.x_hat_apriori = self.Ad @ self.x_hat + self.Bd @ uk_minus_1\n",
        "        self.P_apriori = self.Ad @ self.P @ self.Ad.T + self.G @ self.Qk @ self.G.T\n",
        "        return self.x_hat_apriori\n",
        "        \n",
        "    def update(self, y_measured_k, uk_current):\n",
        "        # Measurement Update (Correction)\n",
        "        # y_measured_k is the measurement at time k\n",
        "        # uk_current is the input applied at time k if D is non-zero\n",
        "        \n",
        "        # Compute Kalman Gain\n",
        "        S_innovation = self.Cd @ self.P_apriori @ self.Cd.T + self.Rk\n",
        "        Kk = self.P_apriori @ self.Cd.T @ np.linalg.inv(S_innovation)\n",
        "        \n",
        "        # Update state estimate\n",
        "        y_predicted = self.Cd @ self.x_hat_apriori + self.Dd @ uk_current\n",
        "        innovation = y_measured_k - y_predicted\n",
        "        self.x_hat = self.x_hat_apriori + Kk @ innovation\n",
        "        \n",
        "        # Update error covariance\n",
        "        I_n = np.eye(self.n_states)\n",
        "        self.P = (I_n - Kk @ self.Cd) @ self.P_apriori\n",
        "        # Numerically more stable Joseph form for P update (optional):\n",
        "        # self.P = (I_n - Kk @ self.Cd) @ self.P_apriori @ (I_n - Kk @ self.Cd).T + Kk @ self.Rk @ Kk.T\n",
        "        \n",
        "        return self.x_hat, self.P\n",
        "\n",
        "    def step(self, uk_prev_for_predict, y_measured_k, uk_curr_for_update):\n",
        "        \"\"\"Combines predict and update steps.\"\"\"\n",
        "        self.predict(uk_prev_for_predict)\n",
        "        self.update(y_measured_k, uk_curr_for_update)\n",
        "        return self.x_hat, self.P"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tuning $Q_K$ and $R_K$\n",
        "\n",
        "*   **$R_K$ (Measurement Noise Covariance):** Reflects sensor accuracy. Diagonal elements are variances of individual sensor noises. Can often be estimated from sensor datasheets or by analyzing sensor readings when the true value is known (e.g., variance of readings around a constant value).\n",
        "*   **$Q_K$ (Process Noise Covariance):** Represents uncertainty in the process model ($A_d, B_d$) and unmeasured disturbances. $G$ maps this abstract noise to how it affects states. $Q_K$ is often a tuning parameter:\n",
        "    *   **Larger $Q_K$ values:** Imply less trust in the model. The filter will rely more on measurements (Kalman gain $K_k$ will be larger), leading to faster response to real state changes but potentially noisier estimates.\n",
        "    *   **Smaller $Q_K$ values:** Imply more trust in the model. The filter will smooth out measurements more (Kalman gain $K_k$ will be smaller), leading to less noisy estimates but potentially lagging true state changes if the model is inaccurate or unmeasured disturbances are significant.\n",
        "\n",
        "Finding the right balance is key. For our double integrator, let's assume $G=I$ initially, meaning process noise affects both position and velocity states directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Kalman Filter Parameters\n",
        "G_kf = np.eye(n_states) # Process noise affects states directly\n",
        "# G_kf = Bd # If process noise enters through input channel\n",
        "\n",
        "# Measurement noise covariance (for position sensor)\n",
        "R_k_val = 0.01**2 # Assume std dev of measurement noise is 0.01\n",
        "Rk_kf = np.array([[R_k_val]]) # p x p matrix (here p=1)\n",
        "\n",
        "# Process noise covariance (TUNING PARAMETERS)\n",
        "q_pos_noise_std = 0.005 # std dev of noise on position state \n",
        "q_vel_noise_std = 0.05  # std dev of noise on velocity state\n",
        "Qk_kf = np.diag([q_pos_noise_std**2, q_vel_noise_std**2]) # n x n matrix\n",
        "\n",
        "# Initial state estimate and covariance for KF\n",
        "x_hat0_kf = np.array([[0.0], [0.0]]) # Initial guess for state\n",
        "P0_kf = np.diag([0.1**2, 0.1**2])   # Uncertainty in initial guess\n",
        "\n",
        "# Instantiate the Kalman Filter\n",
        "kf = KalmanFilter(Ad, Bd, Cd, Dd, G_kf, Qk_kf, Rk_kf, x_hat0_kf, P0_kf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. LMPC with Kalman Filter (Output Feedback MPC)\n",
        "\n",
        "Now we modify the LMPC simulation loop:\n",
        "1.  At time $k$, the plant is at true state $x_{true,k}$.\n",
        "2.  A noisy measurement $y_{m,k} = C x_{true,k} + D u_{true,k-1} + v_k$ is obtained.\n",
        "3.  The Kalman Filter uses $u_{true,k-1}$ (input that led to $x_{true,k}$) for its prediction step, and $y_{m,k}$ and $u_{true,k}$ (if $D \\neq 0$, for $y_{m,k}$'s D-term part) for its update step to get $\\hat{x}_{k|k}$.\n",
        "4.  This $\\hat{x}_{k|k}$ is passed to the MPC controller as the current state $x_k$.\n",
        "5.  MPC computes $u_k^* = u_{k|k}^*$.\n",
        "6.  This $u_k^*$ is applied to the true plant (which also experiences process noise $w_k$) to get $x_{true,k+1}$.\n",
        "7.  Repeat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- LMPC with KF Simulation ---\n",
        "sim_steps_kf = 100\n",
        "\n",
        "# Plant initial conditions\n",
        "x_true_plant = np.array([[0.0], [0.0]]) \n",
        "u_prev_applied_true = np.array([[0.0]]) # Input applied at k-1 to get x_true_plant at k\n",
        "\n",
        "# Kalman Filter re-initialization for each simulation run (if tuning)\n",
        "kf = KalmanFilter(Ad, Bd, Cd, Dd, G_kf, Qk_kf, Rk_kf, x_hat0_kf.copy(), P0_kf.copy())\n",
        "\n",
        "# MPC reference\n",
        "setpoint_kf = 1.0\n",
        "R_traj_target_kf = np.ones((Np * n_outputs, 1)) * setpoint_kf\n",
        "\n",
        "# Data logging\n",
        "X_true_log = np.zeros((n_states, sim_steps_kf + 1))\n",
        "X_hat_log = np.zeros((n_states, sim_steps_kf + 1))\n",
        "Y_measured_log = np.zeros((n_outputs, sim_steps_kf))\n",
        "U_applied_log = np.zeros((n_inputs, sim_steps_kf))\n",
        "P_diag_log = np.zeros((n_states, sim_steps_kf + 1)) # Log diagonal of P_k|k\n",
        "\n",
        "X_true_log[:, 0] = x_true_plant.flatten()\n",
        "X_hat_log[:, 0] = kf.x_hat.flatten()\n",
        "P_diag_log[:, 0] = np.diag(kf.P)\n",
        "\n",
        "# Get H_qp (constant) and f_qp function for MPC\n",
        "H_qp_for_kf_sim, compute_f_qp_for_kf_sim, T_diff_for_kf_sim = \\\n",
        "    build_qp_components_basic(F_mpc, Phi_mpc, Qw, Rw, Sw, Np, n_inputs, n_outputs)\n",
        "\n",
        "# CVXPY QP Solver function (unconstrained for now)\n",
        "def solve_qp_cvxpy_unconstrained(H_qp_mat, f_qp_vec, solver=cp.OSQP):\n",
        "    num_vars_U = H_qp_mat.shape[0]\n",
        "    U_dv = cp.Variable(num_vars_U)\n",
        "    H_qp_symm = 0.5 * (H_qp_mat + H_qp_mat.T)\n",
        "    objective = cp.Minimize(0.5 * cp.quad_form(U_dv, H_qp_symm) + f_qp_vec.flatten() @ U_dv)\n",
        "    problem = cp.Problem(objective)\n",
        "    problem.solve(solver=solver, verbose=False)\n",
        "    if problem.status in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:\n",
        "        return U_dv.value.reshape(-1, 1)\n",
        "    else:\n",
        "        print(f\"QP Solver issue: {problem.status} at a sim step.\")\n",
        "        return np.zeros((num_vars_U,1)) # Fallback: zero control sequence\n",
        "\n",
        "print(f\"Starting LMPC with KF simulation for {sim_steps_kf} steps...\")\n",
        "for k_sim in range(sim_steps_kf):\n",
        "    print(f\"Sim step {k_sim+1}/{sim_steps_kf}\", end='\\r')\n",
        "    \n",
        "    # 1. Plant: Current true state is x_true_plant (which is X_true_log[:, k_sim])\n",
        "    \n",
        "    # 2. Measurement: Simulate noisy measurement from true plant state\n",
        "    # y_m,k = C x_true,k + D u_true,k-1 (if D related to input causing current state)\n",
        "    # or y_m,k = C x_true,k + D u_true,k (if D related to current input about to be applied - not yet known for KF input)\n",
        "    # Let's assume D=0, so y_m,k = C x_true,k + v_k\n",
        "    v_k_noise = np.random.normal(0, np.sqrt(Rk_kf[0,0])) # Measurement noise sample\n",
        "    y_measured = Cd @ x_true_plant + Dd @ u_prev_applied_true + v_k_noise # y_m,k = C x_true,k + v_k (since Dd=0)\n",
        "    Y_measured_log[:, k_sim] = y_measured.flatten()\n",
        "    \n",
        "    # 3. Kalman Filter: \n",
        "    #   uk_prev_for_predict = u_prev_applied_true (input that resulted in x_true_plant)\n",
        "    #   uk_curr_for_update = u_prev_applied_true (if Dd != 0 in y_m = Cx + Du + v, here Dd=0, so it doesn't matter)\n",
        "    x_hat_current, P_current = kf.step(u_prev_applied_true, y_measured, u_prev_applied_true) \n",
        "    X_hat_log[:, k_sim] = x_hat_current.flatten() # Store x_hat_k|k\n",
        "    P_diag_log[:, k_sim] = np.diag(P_current)\n",
        "    \n",
        "    # 4. MPC: Use estimated state x_hat_current\n",
        "    f_qp_for_mpc = compute_f_qp_for_kf_sim(x_hat_current, R_traj_target_kf, u_prev_applied_true)\n",
        "    \n",
        "    # 5. Solve QP\n",
        "    U_optimal_mpc = solve_qp_cvxpy_unconstrained(H_qp_for_kf_sim, f_qp_for_mpc)\n",
        "    \n",
        "    if U_optimal_mpc is None: # Should have been handled by fallback in solver\n",
        "        u_applied_true = u_prev_applied_true\n",
        "    else:\n",
        "        u_applied_true = U_optimal_mpc[0:n_inputs].reshape(n_inputs, 1)\n",
        "    \n",
        "    U_applied_log[:, k_sim] = u_applied_true.flatten()\n",
        "    \n",
        "    # 6. Plant Evolves: Apply u_applied_true to true plant with process noise\n",
        "    w_k_noise = np.random.multivariate_normal([0,0], Qk_kf).reshape(n_states,1) # Process noise sample\n",
        "    x_true_plant_next = Ad @ x_true_plant + Bd @ u_applied_true + G_kf @ w_k_noise\n",
        "    \n",
        "    # Log true state for next iteration\n",
        "    X_true_log[:, k_sim + 1] = x_true_plant_next.flatten()\n",
        "    \n",
        "    # Update for next loop iteration\n",
        "    x_true_plant = x_true_plant_next\n",
        "    u_prev_applied_true = u_applied_true\n",
        "\n",
        "# Final estimate at end of sim\n",
        "X_hat_log[:, sim_steps_kf] = kf.x_hat.flatten()\n",
        "P_diag_log[:, sim_steps_kf] = np.diag(kf.P)\n",
        "\n",
        "print(\"\\nLMPC with KF simulation finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualizing Performance with Kalman Filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "time_sim_kf = np.arange(0, sim_steps_kf * Ts, Ts)\n",
        "time_states_kf = np.arange(0, (sim_steps_kf + 1) * Ts, Ts)\n",
        "\n",
        "plt.figure(figsize=(14, 12))\n",
        "\n",
        "# Position (State x1 and Output y1)\n",
        "plt.subplot(3,2,1)\n",
        "plt.plot(time_states_kf, X_true_log[0,:], 'b-', label='True Position (x1_true)')\n",
        "plt.plot(time_states_kf, X_hat_log[0,:], 'r--', label='Estimated Position (x1_hat)')\n",
        "plt.plot(time_sim_kf, Y_measured_log[0,:], 'gx', markersize=4, alpha=0.6, label='Measured Position (y_m)')\n",
        "plt.axhline(setpoint_kf, color='k', linestyle=':', label='Setpoint')\n",
        "plt.title(f'Output Feedback LMPC w/ KF (Np={Np}, Qw={Qw}, Rw={Rw}, Sw={Sw})')\n",
        "plt.ylabel('Position')\n",
        "plt.grid(True); plt.legend()\n",
        "\n",
        "# Velocity (State x2)\n",
        "plt.subplot(3,2,3)\n",
        "plt.plot(time_states_kf, X_true_log[1,:], 'b-', label='True Velocity (x2_true)')\n",
        "plt.plot(time_states_kf, X_hat_log[1,:], 'r--', label='Estimated Velocity (x2_hat)')\n",
        "plt.ylabel('Velocity'); plt.grid(True); plt.legend()\n",
        "\n",
        "# Control Input\n",
        "plt.subplot(3,2,5)\n",
        "plt.step(time_sim_kf, U_applied_log[0,:], 'k-', where='post', label='Control Input u')\n",
        "plt.ylabel('Input (Force)'); plt.xlabel('Time (s)'); plt.grid(True); plt.legend()\n",
        "\n",
        "# Estimation Errors\n",
        "plt.subplot(3,2,2)\n",
        "plt.plot(time_states_kf, X_true_log[0,:] - X_hat_log[0,:], 'm-', label='Error x1 (Pos)')\n",
        "plt.plot(time_states_kf, 2*np.sqrt(P_diag_log[0,:]), 'm:', label='+-2*std_dev(x1_hat)')\n",
        "plt.plot(time_states_kf, -2*np.sqrt(P_diag_log[0,:]), 'm:')\n",
        "plt.title('State Estimation Errors & Covariance')\n",
        "plt.ylabel('Position Error'); plt.grid(True); plt.legend()\n",
        "\n",
        "plt.subplot(3,2,4)\n",
        "plt.plot(time_states_kf, X_true_log[1,:] - X_hat_log[1,:], 'c-', label='Error x2 (Vel)')\n",
        "plt.plot(time_states_kf, 2*np.sqrt(P_diag_log[1,:]), 'c:', label='+-2*std_dev(x2_hat)')\n",
        "plt.plot(time_states_kf, -2*np.sqrt(P_diag_log[1,:]), 'c:')\n",
        "plt.ylabel('Velocity Error'); plt.xlabel('Time (s)'); plt.grid(True); plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Experimenting with KF Tuning ($Q_K, R_K$)\n",
        "\n",
        "The performance of the Kalman Filter, and consequently the output feedback MPC, is sensitive to the choice of $Q_K$ and $R_K$.\n",
        "\n",
        "*   **If $R_K$ is too small (filter trusts noisy measurements too much):** Estimated states might be noisy, leading to jerky control action.\n",
        "*   **If $R_K$ is too large (filter trusts measurements too little):** Estimation might be slow to respond to true state changes if the model is not perfect, potentially relying too much on an inaccurate model.\n",
        "*   **If $Q_K$ is too small (filter trusts model too much):** If there are unmodeled disturbances or model errors, the filter might diverge or be slow to track true state changes.\n",
        "*   **If $Q_K$ is too large (filter trusts model too little):** Estimates will respond quickly to measurements but might become noisy, similar to having a small $R_K$.\n",
        "\n",
        "**Exercise:**\n",
        "1.  Re-run the simulation with the default $Q_K, R_K$.\n",
        "2.  Try increasing the `R_k_val` significantly (e.g., `0.1**2`). How do the estimates and control action change?\n",
        "3.  Reset `R_k_val`. Try decreasing `q_pos_noise_std` and `q_vel_noise_std` (elements of $Q_K$) significantly (e.g., by a factor of 10). What happens?\n",
        "4.  Try increasing `q_pos_noise_std` and `q_vel_noise_std`. Observe the effect on estimate smoothness and tracking of true states.\n",
        "\n",
        "The plots of estimation error along with the $\\pm 2\\sigma$ bounds (from the diagonal of $P_{k|k}$) can help assess if the filter is well-tuned. Ideally, the true error should mostly lie within these bounds, and the bounds should not be excessively large or small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Key Takeaways\n",
        "\n",
        "*   The Kalman Filter provides a systematic way to estimate system states from noisy measurements in the presence of process noise.\n",
        "*   It operates via a recursive predict-correct cycle.\n",
        "*   Tuning the noise covariance matrices $Q_K$ (process noise) and $R_K$ (measurement noise) is crucial for good estimation performance.\n",
        "*   Integrating a Kalman Filter with LMPC allows for **output feedback MPC**, where the controller uses estimated states instead of assuming full state knowledge.\n",
        "*   The quality of state estimation directly impacts the performance of the MPC controller.\n",
        "\n",
        "This concludes our foundational exploration of LMPC modeling, prediction, optimization, constraint handling, and state estimation. In the next part of the series (**Part 3: Nonlinear MPC**), we will move beyond linear systems and tackle the challenges and opportunities presented by nonlinear dynamics."
      ]
    }
  ]
}